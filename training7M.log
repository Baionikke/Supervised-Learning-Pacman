
            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙
        
 Version information:
  ml-agents: 0.29.0,
  ml-agents-envs: 0.29.0,
  Communicator API: 1.5.0,
  PyTorch: 1.8.1+cu102
[INFO] Connected to Unity environment with package version 2.3.0-exp.2 and communication version 1.5.0
[INFO] Connected new brain: My Behavior?team=0
[INFO] Hyperparameters for behavior name My Behavior: 
	trainer_type:	ppo
	hyperparameters:	
	  batch_size:	32
	  buffer_size:	4096
	  learning_rate:	0.0001
	  beta:	0.005
	  epsilon:	0.23
	  lambd:	0.94
	  num_epoch:	4
	  learning_rate_schedule:	linear
	  beta_schedule:	linear
	  epsilon_schedule:	linear
	network_settings:	
	  normalize:	True
	  hidden_units:	256
	  num_layers:	3
	  vis_encode_type:	resnet
	  memory:	
	    sequence_length:	32
	    memory_size:	512
	  goal_conditioning_type:	hyper
	  deterministic:	False
	reward_signals:	
	  extrinsic:	
	    gamma:	0.995
	    strength:	1.0
	    network_settings:	
	      normalize:	False
	      hidden_units:	128
	      num_layers:	2
	      vis_encode_type:	simple
	      memory:	None
	      goal_conditioning_type:	hyper
	      deterministic:	False
	  curiosity:	
	    gamma:	0.99
	    strength:	0.01
	    network_settings:	
	      normalize:	False
	      hidden_units:	64
	      num_layers:	3
	      vis_encode_type:	simple
	      memory:	None
	      goal_conditioning_type:	hyper
	      deterministic:	False
	    learning_rate:	0.0001
	    encoding_size:	None
	init_path:	None
	keep_checkpoints:	2
	checkpoint_interval:	500000
	max_steps:	500000
	time_horizon:	512
	summary_freq:	1000
	threaded:	False
	self_play:	None
	behavioral_cloning:	
	  demo_path:	Assets/Demonstrations/final/0.demo
	  steps:	500000
	  strength:	0.5
	  samples_per_update:	2048
	  num_epoch:	4
	  batch_size:	32
[INFO] My Behavior. Step: 1000. Time Elapsed: 22.324 s. No episode was completed since last summary. Training.
[INFO] My Behavior. Step: 2000. Time Elapsed: 33.842 s. No episode was completed since last summary. Training.
[INFO] My Behavior. Step: 3000. Time Elapsed: 45.568 s. No episode was completed since last summary. Training.
[INFO] My Behavior. Step: 4000. Time Elapsed: 57.479 s. No episode was completed since last summary. Training.
[INFO] My Behavior. Step: 5000. Time Elapsed: 135.122 s. No episode was completed since last summary. Training.
[INFO] My Behavior. Step: 6000. Time Elapsed: 146.999 s. No episode was completed since last summary. Training.
[INFO] My Behavior. Step: 7000. Time Elapsed: 158.864 s. No episode was completed since last summary. Training.
[INFO] My Behavior. Step: 8000. Time Elapsed: 170.747 s. No episode was completed since last summary. Training.
